{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "UcOPoLTScu4V"
   },
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Adjust the number of parent calls based on the nesting level\n",
    "root_path = str(Path(os.getcwd()).resolve().parent)  \n",
    "sys.path.append(root_path)\n",
    "\n",
    "import model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the model from a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"trained_model/ablima_model_200_iteration.pkl\", 'rb') as f:\n",
    "    loaded_model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def print_topic_word_distribution(model):\n",
    "#     phi = model.calculate_phi_update()  # This gives you the word-topic matrix\n",
    "\n",
    "#     for topic_idx in range(model.num_topics):\n",
    "#         print(f\"Topic #{topic_idx+1}:\\n\")\n",
    "        \n",
    "#         for word_id in range(model.vocab_size):\n",
    "#             word_probability = phi[topic_idx, word_id]\n",
    "#             word = model.id2word[word_id]\n",
    "#             print(f\"{word}: {word_probability:.4f}\")\n",
    "        \n",
    "#         print(\"\\n\\n\")  # Print a newline to separate topics\n",
    "\n",
    "# print_topic_word_distribution(loaded_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<< Topic # 1 >>\n",
      "cause: 0.0148\n",
      "problem: 0.0091\n",
      "doctor: 0.0084\n",
      "patient: 0.0084\n",
      "effect: 0.0082\n",
      "medical: 0.0076\n",
      "good: 0.0071\n",
      "result: 0.0068\n",
      "disease: 0.0066\n",
      "medicine: 0.0063\n",
      "\n",
      "\n",
      "<< Topic # 2 >>\n",
      "people: 0.0095\n",
      "fbi: 0.0092\n",
      "gun: 0.0088\n",
      "government: 0.0081\n",
      "koresh: 0.0073\n",
      "law: 0.0072\n",
      "child: 0.0069\n",
      "state: 0.0066\n",
      "day: 0.0066\n",
      "evidence: 0.0061\n",
      "\n",
      "\n",
      "<< Topic # 3 >>\n",
      "game: 0.0261\n",
      "play: 0.0143\n",
      "team: 0.0141\n",
      "player: 0.0115\n",
      "win: 0.0090\n",
      "year: 0.0090\n",
      "hit: 0.0082\n",
      "baseball: 0.0079\n",
      "score: 0.0070\n",
      "fan: 0.0070\n",
      "\n",
      "\n",
      "<< Topic # 4 >>\n",
      "file: 0.0139\n",
      "image: 0.0113\n",
      "graphic: 0.0108\n",
      "format: 0.0106\n",
      "available: 0.0091\n",
      "version: 0.0089\n",
      "ftp: 0.0085\n",
      "convert: 0.0083\n",
      "color: 0.0076\n",
      "look: 0.0073\n",
      "\n",
      "\n",
      "<< Topic # 5 >>\n",
      "really: 0.0158\n",
      "people: 0.0137\n",
      "thing: 0.0126\n",
      "good: 0.0123\n",
      "tell: 0.0095\n",
      "post: 0.0079\n",
      "look: 0.0078\n",
      "let: 0.0075\n",
      "point: 0.0074\n",
      "read: 0.0073\n",
      "\n",
      "\n",
      "<< Topic # 6 >>\n",
      "hand: 0.0068\n",
      "away: 0.0066\n",
      "little: 0.0063\n",
      "ask: 0.0060\n",
      "later: 0.0059\n",
      "start: 0.0058\n",
      "head: 0.0056\n",
      "saw: 0.0056\n",
      "day: 0.0053\n",
      "leave: 0.0053\n",
      "\n",
      "\n",
      "<< Topic # 7 >>\n",
      "problem: 0.0064\n",
      "small: 0.0058\n",
      "type: 0.0056\n",
      "data: 0.0055\n",
      "end: 0.0051\n",
      "high: 0.0051\n",
      "effect: 0.0049\n",
      "right: 0.0048\n",
      "probably: 0.0048\n",
      "number: 0.0047\n",
      "\n",
      "\n",
      "<< Topic # 8 >>\n",
      "space: 0.0131\n",
      "earth: 0.0079\n",
      "orbit: 0.0074\n",
      "star: 0.0073\n",
      "mission: 0.0073\n",
      "look: 0.0070\n",
      "shuttle: 0.0069\n",
      "new: 0.0067\n",
      "man: 0.0065\n",
      "thing: 0.0065\n",
      "\n",
      "\n",
      "<< Topic # 9 >>\n",
      "work: 0.0144\n",
      "drive: 0.0144\n",
      "card: 0.0115\n",
      "problem: 0.0113\n",
      "run: 0.0109\n",
      "try: 0.0095\n",
      "help: 0.0095\n",
      "disk: 0.0093\n",
      "machine: 0.0083\n",
      "hard: 0.0082\n",
      "\n",
      "\n",
      "<< Topic # 10 >>\n",
      "world: 0.0076\n",
      "source: 0.0072\n",
      "new: 0.0063\n",
      "armenian: 0.0063\n",
      "serdar: 0.0062\n",
      "york: 0.0061\n",
      "argic: 0.0060\n",
      "turkish: 0.0054\n",
      "russian: 0.0053\n",
      "million: 0.0052\n",
      "\n",
      "\n",
      "<< Topic # 11 >>\n",
      "support: 0.0057\n",
      "number: 0.0056\n",
      "state: 0.0053\n",
      "public: 0.0049\n",
      "american: 0.0048\n",
      "today: 0.0048\n",
      "present: 0.0043\n",
      "future: 0.0042\n",
      "work: 0.0042\n",
      "include: 0.0040\n",
      "\n",
      "\n",
      "<< Topic # 12 >>\n",
      "money: 0.0144\n",
      "buy: 0.0141\n",
      "cost: 0.0108\n",
      "people: 0.0107\n",
      "good: 0.0103\n",
      "pay: 0.0093\n",
      "price: 0.0089\n",
      "lot: 0.0085\n",
      "new: 0.0084\n",
      "look: 0.0083\n",
      "\n",
      "\n",
      "<< Topic # 13 >>\n",
      "god: 0.0147\n",
      "christian: 0.0094\n",
      "jesus: 0.0085\n",
      "bible: 0.0076\n",
      "christ: 0.0074\n",
      "church: 0.0070\n",
      "word: 0.0064\n",
      "life: 0.0061\n",
      "sin: 0.0061\n",
      "believe: 0.0058\n",
      "\n",
      "\n",
      "<< Topic # 14 >>\n",
      "right: 0.0088\n",
      "people: 0.0085\n",
      "war: 0.0076\n",
      "jew: 0.0072\n",
      "israel: 0.0066\n",
      "world: 0.0061\n",
      "muslim: 0.0057\n",
      "arab: 0.0055\n",
      "jewish: 0.0052\n",
      "country: 0.0050\n",
      "\n",
      "\n",
      "<< Topic # 15 >>\n",
      "point: 0.0086\n",
      "people: 0.0084\n",
      "mean: 0.0076\n",
      "fact: 0.0065\n",
      "consider: 0.0060\n",
      "believe: 0.0060\n",
      "argument: 0.0059\n",
      "way: 0.0057\n",
      "reason: 0.0057\n",
      "thing: 0.0054\n",
      "\n",
      "\n",
      "<< Topic # 16 >>\n",
      "email: 0.0124\n",
      "university: 0.0114\n",
      "mail: 0.0101\n",
      "information: 0.0096\n",
      "send: 0.0096\n",
      "address: 0.0090\n",
      "post: 0.0081\n",
      "subject: 0.0080\n",
      "group: 0.0079\n",
      "article: 0.0077\n",
      "\n",
      "\n",
      "<< Topic # 17 >>\n",
      "key: 0.0108\n",
      "thing: 0.0106\n",
      "way: 0.0088\n",
      "read: 0.0085\n",
      "clipper: 0.0085\n",
      "work: 0.0084\n",
      "government: 0.0078\n",
      "chip: 0.0078\n",
      "people: 0.0076\n",
      "right: 0.0073\n",
      "\n",
      "\n",
      "<< Topic # 18 >>\n",
      "email: 0.0139\n",
      "sale: 0.0134\n",
      "sell: 0.0114\n",
      "ask: 0.0108\n",
      "price: 0.0101\n",
      "include: 0.0089\n",
      "new: 0.0088\n",
      "condition: 0.0079\n",
      "offer: 0.0079\n",
      "computer: 0.0075\n",
      "\n",
      "\n",
      "<< Topic # 19 >>\n",
      "car: 0.0125\n",
      "good: 0.0117\n",
      "bike: 0.0088\n",
      "work: 0.0079\n",
      "try: 0.0077\n",
      "look: 0.0072\n",
      "problem: 0.0072\n",
      "right: 0.0071\n",
      "engine: 0.0069\n",
      "new: 0.0068\n",
      "\n",
      "\n",
      "<< Topic # 20 >>\n",
      "window: 0.0146\n",
      "run: 0.0128\n",
      "program: 0.0115\n",
      "problem: 0.0101\n",
      "file: 0.0097\n",
      "work: 0.0092\n",
      "help: 0.0085\n",
      "application: 0.0079\n",
      "try: 0.0078\n",
      "user: 0.0072\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def print_top_words_per_topic(model, top_n=10):\n",
    "    phi = model.calculate_phi_update()  # This gives you the word-topic matrix\n",
    "\n",
    "    for topic_idx in range(model.num_topics):\n",
    "        print(f\"<< Topic # {topic_idx+1} >>\")\n",
    "\n",
    "        # Get the top N word indices for the topic sorted by probability\n",
    "        top_word_indices = phi[topic_idx].argsort()[-top_n:][::-1]\n",
    "        \n",
    "        for word_id in top_word_indices:\n",
    "            word_probability = phi[topic_idx, word_id]\n",
    "            word = model.id2word[word_id]\n",
    "            print(f\"{word}: {word_probability:.4f}\")\n",
    "\n",
    "        print(\"\\n\")  # Print a newline to separate topics\n",
    "\n",
    "# After running your model...\n",
    "print_top_words_per_topic(loaded_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract word for each topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After you've run Gibbs sampling\n",
    "word_topic_matrix = loaded_model.word_topic_matrix\n",
    "word_topic_sum = word_topic_matrix.sum(axis=1)[:, np.newaxis]\n",
    "word_topic_dist = word_topic_matrix / word_topic_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the top N words for each topic\n",
    "N_TOP_WORDS = 50\n",
    "\n",
    "ALL_TOPIC_WORDS = []\n",
    "for i in range(loaded_model.num_topics):\n",
    "    top_words_idx = word_topic_dist[i].argsort()[-N_TOP_WORDS:][::-1]\n",
    "    top_words = [loaded_model.id2word[idx] for idx in top_words_idx]\n",
    "\n",
    "    ALL_TOPIC_WORDS.append(top_words)\n",
    "\n",
    "    # print(f\"Topic {i + 1}: {', '.join(top_words)} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_dic = {}\n",
    "\n",
    "for topic_words in ALL_TOPIC_WORDS:\n",
    "  for word in topic_words:\n",
    "    if word in word_dic:\n",
    "      word_dic[word] = word_dic[word] + 1\n",
    "    else:\n",
    "      word_dic[word] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_dic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the author-topic distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the author_topic_matrix to get author-topic distribution\n",
    "\n",
    "# Compute the sum of rows in author_topic_matrix\n",
    "author_topic_sum = loaded_model.author_topic_matrix.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "# Replace zero sums with a small epsilon value\n",
    "epsilon = 1e-10\n",
    "author_topic_sum[author_topic_sum == 0] = epsilon\n",
    "\n",
    "# Perform element-wise division\n",
    "author_topic_dist = loaded_model.author_topic_matrix / author_topic_sum\n",
    "\n",
    "# Visualize the top N topics for each author\n",
    "N_TOP_TOPICS = 3\n",
    "top_topics_list = []\n",
    "for i, author in enumerate(loaded_model.authors):\n",
    "    top_topics_idx = author_topic_dist[i].argsort()[-N_TOP_TOPICS:][::-1]\n",
    "    top_topics_list.append(top_topics_idx)\n",
    "    # print(f\"Author {i+1} => {author} : Topic IDs {top_topics_idx} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>authors</th>\n",
       "      <th>topics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lerxst@wam.umd.edu (where's my thing)</td>\n",
       "      <td>[11, 14, 18]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>guykuo@carson.u.washington.edu (Guy Kuo)</td>\n",
       "      <td>[7, 4, 10]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>twillis@ec.ecn.purdue.edu (Thomas E Willis)</td>\n",
       "      <td>[4, 19, 18]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jgreen@amber (Joe Green)</td>\n",
       "      <td>[13, 4, 5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jcm@head-cfa.harvard.edu (Jonathan McDowell)</td>\n",
       "      <td>[14, 5, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>dfo@vttoulu.tko.vtt.fi (Foxvog Douglas)</td>\n",
       "      <td>[0, 4, 13]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>bmdelane@quads.uchicago.edu (brian manning del...</td>\n",
       "      <td>[1, 14, 16]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>bgrubb@dante.nmsu.edu (GRUBB)</td>\n",
       "      <td>[8, 4, 13]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>holmes7000@iscsvax.uni.edu</td>\n",
       "      <td>[19, 6, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>kerr@ux1.cso.uiuc.edu (Stan Kerr)</td>\n",
       "      <td>[3, 4, 19]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>irwin@cmptrc.lonestar.org (Irwin Arnstein)</td>\n",
       "      <td>[11, 3, 17]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>david@terminus.ericsson.se (David Bold)</td>\n",
       "      <td>[8, 3, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>rodc@fc.hp.com (Rod Cerkoney)</td>\n",
       "      <td>[14, 13, 19]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>dbm0000@tm0006.lerc.nasa.gov (David B. Mckissock)</td>\n",
       "      <td>[3, 2, 18]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>jllee@acsu.buffalo.edu (Johnny L Lee)</td>\n",
       "      <td>[4, 14, 12]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>mathew</td>\n",
       "      <td>[17, 13, 6]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ab@nova.cc.purdue.edu (Allen B)</td>\n",
       "      <td>[1, 19, 8]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>CPKJP@vm.cc.latech.edu (Kevin Parker)</td>\n",
       "      <td>[15, 17, 14]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ritley@uimrl7.mrl.uiuc.edu ()</td>\n",
       "      <td>[17, 11, 5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>abarden@tybse1.uucp (Ann Marie Barden)</td>\n",
       "      <td>[17, 2, 7]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              authors        topics\n",
       "0               lerxst@wam.umd.edu (where's my thing)  [11, 14, 18]\n",
       "1            guykuo@carson.u.washington.edu (Guy Kuo)    [7, 4, 10]\n",
       "2         twillis@ec.ecn.purdue.edu (Thomas E Willis)   [4, 19, 18]\n",
       "3                            jgreen@amber (Joe Green)    [13, 4, 5]\n",
       "4        jcm@head-cfa.harvard.edu (Jonathan McDowell)    [14, 5, 0]\n",
       "5             dfo@vttoulu.tko.vtt.fi (Foxvog Douglas)    [0, 4, 13]\n",
       "6   bmdelane@quads.uchicago.edu (brian manning del...   [1, 14, 16]\n",
       "7                       bgrubb@dante.nmsu.edu (GRUBB)    [8, 4, 13]\n",
       "8                          holmes7000@iscsvax.uni.edu    [19, 6, 1]\n",
       "9                   kerr@ux1.cso.uiuc.edu (Stan Kerr)    [3, 4, 19]\n",
       "10         irwin@cmptrc.lonestar.org (Irwin Arnstein)   [11, 3, 17]\n",
       "11            david@terminus.ericsson.se (David Bold)     [8, 3, 2]\n",
       "12                      rodc@fc.hp.com (Rod Cerkoney)  [14, 13, 19]\n",
       "13  dbm0000@tm0006.lerc.nasa.gov (David B. Mckissock)    [3, 2, 18]\n",
       "14              jllee@acsu.buffalo.edu (Johnny L Lee)   [4, 14, 12]\n",
       "15                                             mathew   [17, 13, 6]\n",
       "16                    ab@nova.cc.purdue.edu (Allen B)    [1, 19, 8]\n",
       "17              CPKJP@vm.cc.latech.edu (Kevin Parker)  [15, 17, 14]\n",
       "18                      ritley@uimrl7.mrl.uiuc.edu ()   [17, 11, 5]\n",
       "19             abarden@tybse1.uucp (Ann Marie Barden)    [17, 2, 7]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_topics_of_authors_df = pd.DataFrame({'authors': loaded_model.authors, 'topics': top_topics_list})\n",
    "top_topics_of_authors_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>authors</th>\n",
       "      <th>topics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2079</th>\n",
       "      <td>lmvec@westminster.ac.uk (William Hargreaves)</td>\n",
       "      <td>[8, 19, 11]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           authors       topics\n",
       "2079  lmvec@westminster.ac.uk (William Hargreaves)  [8, 19, 11]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_topics_of_authors_df[top_topics_of_authors_df['authors'] == 'lmvec@westminster.ac.uk (William Hargreaves)']\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "UcOPoLTScu4V",
    "S_BBNjjzc4m5",
    "c0cAeBowGUVP"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "lda-implementation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "1669881b8e0ee381f1d44208a6e6b4675430ed382f288976bd9acdbb8db18405"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
